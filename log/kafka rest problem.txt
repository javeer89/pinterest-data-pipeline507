[ec2-user@ip-172-31-43-131 bin]$ ./kafka-rest-start  /home/ec2-user/confluent-7.2.0/etc/kafka-rest/kafka-rest.properties
OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N
log4j:ERROR setFile(null,true) call failed.
java.io.FileNotFoundException: /kafka-rest.log (Permission denied)
        at java.io.FileOutputStream.open0(Native Method)
        at java.io.FileOutputStream.open(FileOutputStream.java:270)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:133)
        at org.apache.log4j.FileAppender.setFile(FileAppender.java:282)
        at org.apache.log4j.RollingFileAppender.setFile(RollingFileAppender.java:200)
        at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:166)
        at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:284)
        at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:160)
        at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:100)
        at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:802)
        at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:738)
        at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:630)
        at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:516)
        at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:577)
        at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:504)
        at org.apache.log4j.LogManager.<clinit>(LogManager.java:119)
        at org.slf4j.impl.Reload4jLoggerFactory.<init>(Reload4jLoggerFactory.java:67)
        at org.slf4j.impl.StaticLoggerBinder.<init>(StaticLoggerBinder.java:72)
        at org.slf4j.impl.StaticLoggerBinder.<clinit>(StaticLoggerBinder.java:45)
        at org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)
        at org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)
        at org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)
        at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)
        at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)
        at io.confluent.kafkarest.KafkaRestMain.<clinit>(KafkaRestMain.java:25)
[2024-01-28 19:27:30,387] INFO KafkaRestConfig values:
        access.control.allow.headers =
        access.control.allow.methods =
        access.control.allow.origin =
        access.control.skip.options = true
        advertised.listeners = []
        api.endpoints.allowlist = []
        api.endpoints.blocklist = []
        api.v2.enable = true
        api.v3.enable = true
        api.v3.produce.rate.limit.cache.expiry.ms = 3600000
        api.v3.produce.rate.limit.enabled = false
        api.v3.produce.rate.limit.max.bytes.global.per.sec = 10000000
        api.v3.produce.rate.limit.max.bytes.per.sec = 10000000
        api.v3.produce.rate.limit.max.requests.global.per.sec = 10000
        api.v3.produce.rate.limit.max.requests.per.sec = 10000
        api.v3.produce.response.thread.pool.size = 1
        authentication.method = NONE
        authentication.realm =
        authentication.roles = [*]
        authentication.skip.paths = []
        bootstrap.servers =
        client.init.timeout.ms = 60000
        client.sasl.kerberos.kinit.cmd = /usr/bin/kinit
        client.sasl.kerberos.min.time.before.relogin = 60000
        client.sasl.kerberos.service.name =
        client.sasl.kerberos.ticket.renew.jitter = 0.05
        client.sasl.kerberos.ticket.renew.window.factor = 0.8
        client.sasl.mechanism = AWS_MSK_IAM
        client.security.protocol = SASL_SSL
        client.ssl.cipher.suites =
        client.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
        client.ssl.endpoint.identification.algorithm =
        client.ssl.key.password = [hidden]
        client.ssl.keymanager.algorithm = SunX509
        client.ssl.keystore.location =
        client.ssl.keystore.password = [hidden]
        client.ssl.keystore.type = JKS
        client.ssl.protocol = TLS
        client.ssl.provider =
        client.ssl.trustmanager.algorithm = PKIX
        client.ssl.truststore.location =
        client.ssl.truststore.password = [hidden]
        client.ssl.truststore.type = JKS
        client.timeout.ms = 500
        client.zk.session.timeout.ms = 30000
        compression.enable = true
        confluent.resource.name.authority =
        consumer.instance.timeout.ms = 300000
        consumer.iterator.backoff.ms = 50
        consumer.iterator.timeout.ms = 1
        consumer.request.max.bytes = 67108864
        consumer.request.timeout.ms = 1000
        consumer.threads = 50
        csrf.prevention.enable = false
        csrf.prevention.token.endpoint = /csrf
        csrf.prevention.token.expiration.minutes = 30
        csrf.prevention.token.max.entries = 10000
        debug = false
        dos.filter.delay.ms = 100
        dos.filter.enabled = false
        dos.filter.insert.headers = true
        dos.filter.ip.whitelist = []
        dos.filter.managed.attr = false
        dos.filter.max.idle.tracker.ms = 30000
        dos.filter.max.requests.ms = 30000
        dos.filter.max.requests.per.connection.per.sec = 25
        dos.filter.max.requests.per.sec = 25
        dos.filter.max.wait.ms = 50
        dos.filter.throttle.ms = 30000
        dos.filter.throttled.requests = 5
        fetch.min.bytes = -1
        host.name =
        http2.enabled = true
        id =
        idle.timeout.ms = 30000
        kafka.rest.resource.extension.class = []
        listener.protocol.map = []
        listeners = []
        metric.reporters = []
        metrics.jmx.prefix = kafka.rest
        metrics.num.samples = 2
        metrics.sample.window.ms = 30000
        metrics.tag.map = []
        nosniff.prevention.enable = false
        port = 8082
        producer.threads = 5
        proxy.protocol.enabled = false
        rate.limit.backend = guava
        rate.limit.costs =
        rate.limit.default.cost = 1
        rate.limit.enable = false
        rate.limit.permits.per.sec = 50
        rate.limit.timeout.ms = 0
        reject.options.request = false
        request.logger.name = io.confluent.rest-utils.requests
        request.queue.capacity = 2147483647
        request.queue.capacity.growby = 64
        request.queue.capacity.init = 128
        resource.extension.classes = []
        response.http.headers.config =
        response.mediatype.default = application/json
        response.mediatype.preferred = [application/json, application/vnd.kafka.v2+json]
        rest.servlet.initializor.classes = []
        schema.registry.url = http://localhost:8081
        shutdown.graceful.ms = 1000
        simpleconsumer.pool.size.max = 25
        simpleconsumer.pool.timeout.ms = 1000
        ssl.cipher.suites = []
        ssl.client.auth = false
        ssl.client.authentication = NONE
        ssl.enabled.protocols = []
        ssl.endpoint.identification.algorithm = null
        ssl.key.password = [hidden]
        ssl.keymanager.algorithm =
        ssl.keystore.location =
        ssl.keystore.password = [hidden]
        ssl.keystore.reload = false
        ssl.keystore.type = JKS
        ssl.keystore.watch.location =
        ssl.protocol = TLS
        ssl.provider =
        ssl.trustmanager.algorithm =
        ssl.truststore.location =
        ssl.truststore.password = [hidden]
        ssl.truststore.type = JKS
        thread.pool.max = 200
        thread.pool.min = 8
        websocket.path.prefix = /ws
        websocket.servlet.initializor.classes = []
        zookeeper.connect =
 (io.confluent.kafkarest.KafkaRestConfig:376)
[2024-01-28 19:27:30,528] INFO Logging initialized @1131ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-01-28 19:27:30,655] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer:605)
[2024-01-28 19:27:30,803] WARN DEPRECATION warning: `listeners` configuration is not configured. Falling back to the deprecated `port` configuration. (io.confluent.rest.ApplicationServer:166)
[2024-01-28 19:27:30,812] INFO Adding listener: http://0.0.0.0:8082 (io.confluent.rest.ApplicationServer:518)
[2024-01-28 19:27:31,397] ERROR Server died unexpectedly:  (io.confluent.kafkarest.KafkaRestMain:54)
java.lang.RuntimeException: Atleast one of bootstrap.servers or zookeeper.connect needs to be configured
        at io.confluent.kafkarest.KafkaRestApplication.setupResources(KafkaRestApplication.java:88)
        at io.confluent.kafkarest.KafkaRestApplication.setupResources(KafkaRestApplication.java:50)
        at io.confluent.rest.Application.configureHandler(Application.java:286)
        at io.confluent.rest.ApplicationServer.doStart(ApplicationServer.java:267)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)
        at io.confluent.rest.Application.start(Application.java:734)
        at io.confluent.kafkarest.KafkaRestMain.main(KafkaRestMain.java:47)